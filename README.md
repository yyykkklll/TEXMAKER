# Robust Person Re-Identification via MLLM-Supervised Feature Decoupling
[![LaTeX](https://img.shields.io/badge/LaTeX-008080?style=for-the-badge&logo=latex&logoColor=white)](https://www.latex-project.org/)

This repository contains the official LaTeX source code for our paper:

**Robust Person Re-Identification via MLLM-Supervised Feature Decoupling**

***Author**: KeLong Yan*

***arXiv :**To be determined*
***Gthub Code:***[yyykkklll/Text-based-Person-Retrieval_V3: ðŸŽ“åŸºäºŽæ–‡æœ¬æŒ‡å¯¼çš„è¡Œäººé‡è¯†åˆ«ï¼ˆText-to-Image ReIDï¼‰æ¨¡åž‹ï¼Œé‡‡ç”¨ ViT + BERT æž¶æž„ï¼Œå¹¶èžåˆé—¨æŽ§æœºåˆ¶ä¸Žèº«ä»½-è¡£ç‰©è§£çº ç¼ æŠ€æœ¯ã€‚æ¨¡åž‹å·²å®žçŽ°å¤šä¸ªæ•°æ®é›†çš„è®­ç»ƒä¸Žè¯„ä¼°ï¼ŒåŽç»­å°†æŒç»­ä¼˜åŒ–å’Œæ‰©å±•æž¶æž„ã€‚ðŸš€ðŸ“š](https://github.com/yyykkklll/Text-based-Person-Retrieval_V3)

---

## Abstract

> The challenge of fine-grained semantic alignment contin ues to hinder Text-to-Image Person Re-Identification, where clothing-induced interference and a persistent modality gap degrade retrieval accuracy. In this paper, we propose a novel framework to resolve this issue, centered on MLLM supervised feature decoupling. Our framework introduces two core components: a Bidirectional Decoupling Align ment Module and a Mamba State Space Model for efficient fusion. To obtain high-quality, fine-grained supervision, we f irst employ a Multimodal Large Language Model to auto matically generate separate identity and clothing descrip tions. These descriptions then guide our decoupling module, which utilizes bidirectional attention and a gated weight ing strategy to meticulously disentangle visual features into identity and clothing subspaces. To enforce this separation and ensure identity purity, we design a multi-task loss strat egy combining an adversarial lossâ€”to actively suppress the influence of clothing-related featuresâ€”and a kernel-based orthogonal constraint to ensure statistical independence. Furthermore, we are the first to integrate the Mamba State Space Model into cross-modal Re-ID as an efficient fusion module. By leveraging its linear-time complexity and pro f iciency in modeling long-range dependencies, it facilitates deep contextual interactions across modalities while avoid ing the quadratic complexity of Transformers. Comprehen sive experiments on multiple benchmark datasets reveal that our proposed method achieves superior performance com pared to leading contemporary methods, proving its effec tiveness and robustness.

## Framework

Our core approach involves decoupling traditionally coupled features (Figure a) into separate components (Figure b). We utilize the refined text generated by MLLM (identity/clothing) as supervision to guide the BDAM module in learning distinct feature representations.

### Detailed Architecture

The figure below illustrates the detailed workflow of our proposed method, encompassing the BDAM module, the MLLM text generation process, and the multi-task loss employed for forced decoupling.

![](C:\Users\Administrator\Desktop\Paper\images\frame.png)

## Warehouse Contents

This repository contains all the LaTeX source files required to compile our paper, including:

* `main.tex`: Main .tex file.
* `*.bib`: References document.
* `figures/`: Includes all images and charts used in the paper.

